# -*- coding: utf-8 -*-
"""Cópia de Classificacao_games.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RyZgZcF3DiQwqgAfCaRd6qhqyoLcow0t

# Classificação de conteúdo ofensivo em Foruns de games
"""

import pandas as pd
import numpy as np

"""Montando drive do Google"""

from google.colab import drive
drive.mount('/content/drive')

path = "/content/drive/MyDrive/TCC/dataset.csv"

dados = pd.read_csv(path)

dados.head()

dados.isnull().sum()

"""Organizando para treinar apenas SPAN E NÃO SPAN """

dados['Span'].value_counts()

dados_nao_span = dados.query('(Span == 0)').sample(n=918)
dados_span = dados.query('(Span == 1)').sample(n=918)

dados_filtrados = pd.concat([dados_span, dados_nao_span])

dados_filtrados['Span'].value_counts()

"""Organizando para treinar apenas OFENSIVO E NÃO OFENSIVO"""

dados['Ofensivo'].value_counts()

dados_nao_ofensivos = dados.query('(Ofensivo == 0)').sample(n=500)
dados_ofensivos = dados.query('(Ofensivo == 1)')

dados_filtrados = pd.concat([dados_ofensivos, dados_nao_ofensivos])

dados_filtrados['Ofensivo'].value_counts()

"""Realizar a transformação de dados categóricos em numéricos manualmente."""

dataset = dados_filtrados.copy()

#replace - substitui os valores um DataFrame por outros valores de forma dinâmica.
dataset['Span'].replace({False:0, True: 1}, inplace=True)
dataset['Portugues'].replace({False:0, True: 1}, inplace=True)
dataset['Racismo'].replace({False:0, True: 1}, inplace=True)
dataset['Ofensivo'].replace({False:0, True: 1}, inplace=True)
dataset['Não ofensivo'].replace({False:0, True: 1}, inplace=True)
dataset['Homofobia'].replace({False:0, True: 1}, inplace=True)
dataset['Xenofobia'].replace({False:0, True: 1}, inplace=True)
dataset['Sexismo'].replace({False:0, True: 1}, inplace=True)

#inplace: altera definitivamente, padrão é none.

dataset.head()

"""Selecionando os dados de para o experimento: Detecção de linguagem ofensiva"""

#RODAR RESULTADOS SOMENTE SPAN

X = dataset.iloc[:, 0].values
y = dataset.iloc[:, 1].values

#RODAR RESULTADOS SOMENTE OFENSIVOS

X = dataset.iloc[:, 0].values
y = dataset.iloc[:, 4].values

X

y

"""Base de Treino e Teste"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression

x_treino, x_teste, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 123)

vectorizer = TfidfVectorizer()
X_train_tfidf = vectorizer.fit_transform(x_treino)
X_test_tfidf = vectorizer.transform(x_teste)

x_treino.shape

x_teste.shape

"""Treinamento SVM"""

svm = SVC()
svm.fit(X_train_tfidf, y_train)
y_pred_svm = svm.predict(X_test_tfidf)

svm_precision = precision_score(y_test, y_pred_svm)
svm_recall = recall_score(y_test, y_pred_svm)
svm_f1 = f1_score(y_test, y_pred_svm)

print(f'Precisão: {svm_precision}, Recall: {svm_recall} e F1 Score: {svm_f1}')

"""Treinamento Naive Bayes"""

nb = MultinomialNB()
nb.fit(X_train_tfidf, y_train)
y_pred_nb = nb.predict(X_test_tfidf)

nb_precision = precision_score(y_test, y_pred_nb)
nb_recall = recall_score(y_test, y_pred_nb)
nb_f1 = f1_score(y_test, y_pred_nb)

print(f'Precisão: {nb_precision}, Recall: {nb_recall} e F1 Score: {nb_f1}')

"""Regressão logística"""

lr = LogisticRegression()
lr.fit(X_train_tfidf, y_train)
y_pred_lr = lr.predict(X_test_tfidf)

lr_precision = precision_score(y_test, y_pred_lr)
lr_recall = recall_score(y_test, y_pred_lr)
lr_f1 = f1_score(y_test, y_pred_lr)

print(f'Precisão: {lr_precision}, Recall: {lr_recall} e F1 Score: {lr_f1}')

"""Treinamento LSTM"""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense

tokenizer = Tokenizer(num_words=10000)
tokenizer.fit_on_texts(x_treino)
X_train_lstm = tokenizer.texts_to_sequences(x_treino)
X_test_lstm = tokenizer.texts_to_sequences(x_teste)
X_train_lstm = pad_sequences(X_train_lstm, maxlen=100)
X_test_lstm = pad_sequences(X_test_lstm, maxlen=100)

lstm = Sequential()
lstm.add(Embedding(input_dim=10000, output_dim=64, input_length=100))
lstm.add(LSTM(64))
lstm.add(Dense(1, activation='sigmoid'))
lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
lstm.fit(X_train_lstm, y_train, epochs=50, batch_size=32, validation_data=(X_test_lstm, y_test))
y_pred_lstm = lstm.predict(X_test_lstm)
y_pred_lstm = [1 if pred > 0.5 else 0 for pred in y_pred_lstm]

lstm_precision = precision_score(y_test, y_pred_lstm)
lstm_recall = recall_score(y_test, y_pred_lstm)
lstm_f1 = f1_score(y_test, y_pred_lstm)

print(f'Precisão: {lstm_precision}, Recall: {lstm_recall} e F1 Score: {lstm_f1}')

"""Treinamento BERT"""

!pip install transformers

from transformers import BertTokenizer, TFBertForSequenceClassification
import tensorflow as tf

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
X_train_bert = tokenizer(x_treino.tolist(), padding=True, truncation=True, return_tensors="tf")
X_test_bert = tokenizer(x_teste.tolist(), padding=True, truncation=True, return_tensors="tf")

bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)
loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
metrics = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')
bert_model.compile(optimizer=optimizer, loss=loss, metrics=[metrics])
bert_model.fit(dict(X_train_bert), y_train, epochs=3, batch_size=32)
y_pred_bert = np.argmax(bert_model.predict(X_test_bert)[0], axis=-1)

bert_precision = precision_score(y_test, y_pred_bert)
bert_recall = recall_score(y_test, y_pred_bert)
bert_f1 = f1_score(y_test, y_pred_bert)